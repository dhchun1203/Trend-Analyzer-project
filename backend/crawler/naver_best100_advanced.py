from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import re
import sys
import os

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from db.mongo import collection
    MONGODB_AVAILABLE = True
    print("âœ… MongoDB ì—°ê²° ì„±ê³µ")
except ImportError:
    MONGODB_AVAILABLE = False
    print("âš ï¸ MongoDB ì—°ê²° ì‹¤íŒ¨ - ë°ì´í„°ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤")

def crawl_naver_best100_advanced():
    print("ğŸš€ ë„¤ì´ë²„ ë² ìŠ¤íŠ¸ 100 í¬ë¡¤ë§ ì‹œì‘ (ê³ ê¸‰ ë²„ì „)")
    
    options = webdriver.ChromeOptions()
    # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ ë¹„í™œì„±í™” (ë””ë²„ê¹…ìš©)
    # options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
    # ìë™í™” ê°ì§€ ë°©ì§€
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    
    try:
        # ë©”ì¸ URLë¡œ ì ‘ì†
        url = "https://shopping.naver.com/best100v2/main.naver"
        print(f"ğŸ” URL ì ‘ì†: {url}")
        driver.get(url)
        
        # ì¶©ë¶„í•œ ë¡œë”© ì‹œê°„ ëŒ€ê¸°
        print("â³ í˜ì´ì§€ ë¡œë”© ëŒ€ê¸° ì¤‘...")
        time.sleep(10)
        
        # í˜ì´ì§€ ìŠ¤í¬ë¡¤ (ë™ì  ì½˜í…ì¸  ë¡œë”© ìœ ë„)
        print("ğŸ“œ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(3)
        driver.execute_script("window.scrollTo(0, 0);")
        time.sleep(2)
        
        # í˜„ì¬ í˜ì´ì§€ ìƒíƒœ í™•ì¸
        page_source = driver.page_source
        print(f"ğŸ“„ HTML ê¸¸ì´: {len(page_source)}")
        
        # HTML ë‚´ìš© ì¼ë¶€ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        print("ğŸ” HTML ë‚´ìš© ì¼ë¶€:")
        print(page_source[:1000])
        
        soup = BeautifulSoup(page_source, "html.parser")
        
        # 1. ëª¨ë“  ì´ë¯¸ì§€ íƒœê·¸ ì°¾ê¸°
        all_images = soup.find_all("img")
        print(f"ğŸ“¸ ì „ì²´ ì´ë¯¸ì§€ ê°œìˆ˜: {len(all_images)}")
        
        # 2. ëª¨ë“  ë§í¬ íƒœê·¸ ì°¾ê¸°
        all_links = soup.find_all("a")
        print(f"ğŸ”— ì „ì²´ ë§í¬ ê°œìˆ˜: {len(all_links)}")
        
        # 3. ìƒí’ˆ ê´€ë ¨ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ìš”ì†Œë“¤ ì°¾ê¸°
        product_keywords = ["ìƒí’ˆ", "ì œí’ˆ", "ê°€ê²©", "ì›", "â‚©", "êµ¬ë§¤", "ì¥ë°”êµ¬ë‹ˆ", "ì°œ"]
        product_elements = []
        
        for keyword in product_keywords:
            elements = soup.find_all(text=re.compile(keyword, re.IGNORECASE))
            if elements:
                product_elements.extend(elements)
        
        print(f"ğŸ›ï¸ ìƒí’ˆ ê´€ë ¨ í…ìŠ¤íŠ¸ ìš”ì†Œ ê°œìˆ˜: {len(product_elements)}")
        
        # 4. ìˆ«ìì™€ ì›í™” ê¸°í˜¸ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ ì°¾ê¸° (ê°€ê²© ì •ë³´)
        price_pattern = re.compile(r'[\d,]+ì›')
        price_elements = soup.find_all(text=price_pattern)
        print(f"ğŸ’° ê°€ê²© ì •ë³´ ìš”ì†Œ ê°œìˆ˜: {len(price_elements)}")
        
        # 5. ì‹¤ì œ ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ ì‹œë„
        data_list = []
        
        # ë°©ë²• 1: ì´ë¯¸ì§€ì™€ ë§í¬ê°€ ìˆëŠ” ìš”ì†Œë“¤ ì°¾ê¸°
        print("\nğŸ¯ ë°©ë²• 1: ì´ë¯¸ì§€+ë§í¬ ì¡°í•©ìœ¼ë¡œ ìƒí’ˆ ì°¾ê¸°")
        for i, img in enumerate(all_images[:50]):  # ì²˜ìŒ 50ê°œë§Œ ì‹œë„
            try:
                # ì´ë¯¸ì§€ ì£¼ë³€ì˜ ë§í¬ ì°¾ê¸°
                parent = img.parent
                link_tag = None
                
                # ë¶€ëª¨ ìš”ì†Œì—ì„œ ë§í¬ ì°¾ê¸°
                for _ in range(5):  # ìµœëŒ€ 5ë‹¨ê³„ ìƒìœ„ë¡œ ê²€ìƒ‰
                    if parent:
                        link_tag = parent.find("a")
                        if link_tag:
                            break
                        parent = parent.parent
                
                if link_tag and img.get("alt"):
                    title = img.get("alt", "").strip()
                    image_url = img.get("src", "")
                    link = link_tag.get("href", "")
                    
                    # ê°€ê²© ì •ë³´ ì°¾ê¸°
                    price = "ê°€ê²© ì—†ìŒ"
                    price_parent = img.parent
                    for _ in range(3):
                        if price_parent:
                            price_text = price_parent.get_text()
                            price_match = price_pattern.search(price_text)
                            if price_match:
                                price = price_match.group()
                                break
                            price_parent = price_parent.parent
                    
                    if title and len(title) > 2:  # ì˜ë¯¸ìˆëŠ” ì œëª©ì¸ ê²½ìš°ë§Œ
                        item = {
                            "rank": i + 1,
                            "product_name": title,
                            "price": price,
                            "product_url": link,
                            "image_url": image_url,
                            "mall_name": "",
                            "category": "ì „ì²´"
                        }
                        data_list.append(item)
                        print(f"   {i+1}. {title[:30]}... - {price}")
                
            except Exception as e:
                continue
        
        # ë°©ë²• 2: ë§í¬ê°€ ìˆëŠ” ìš”ì†Œë“¤ì—ì„œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
        if len(data_list) < 10:
            print("\nğŸ¯ ë°©ë²• 2: ë§í¬ ê¸°ë°˜ìœ¼ë¡œ ìƒí’ˆ ì°¾ê¸°")
            for i, link in enumerate(all_links[:100]):
                try:
                    link_text = link.get_text().strip()
                    link_href = link.get("href", "")
                    
                    # ìƒí’ˆ ë§í¬ì¸ì§€ í™•ì¸ (shopping.naver.com í¬í•¨)
                    if "shopping.naver.com" in link_href and link_text:
                        # ë§í¬ ì£¼ë³€ì˜ ì´ë¯¸ì§€ ì°¾ê¸°
                        img_tag = link.find("img")
                        title = img_tag.get("alt", "") if img_tag else link_text
                        image_url = img_tag.get("src", "") if img_tag else ""
                        
                        # ê°€ê²© ì •ë³´ ì°¾ê¸°
                        price = "ê°€ê²© ì—†ìŒ"
                        price_text = link.get_text()
                        price_match = price_pattern.search(price_text)
                        if price_match:
                            price = price_match.group()
                        
                        if title and len(title) > 2:
                            item = {
                                "rank": len(data_list) + 1,
                                "product_name": title,
                                "price": price,
                                "product_url": link_href,
                                "image_url": image_url,
                                "mall_name": "",
                                "category": "ì „ì²´"
                            }
                            data_list.append(item)
                            print(f"   {len(data_list)}. {title[:30]}... - {price}")
                
                except Exception as e:
                    continue
        
        # 6. ê²°ê³¼ ì •ë¦¬
        print(f"\nğŸ“Š ì´ {len(data_list)}ê°œ ìƒí’ˆ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ!")
        
        # 7. MongoDB ì €ì¥ (ê°€ëŠ¥í•œ ê²½ìš°ì—ë§Œ)
        if data_list and MONGODB_AVAILABLE:
            try:
                collection.delete_many({"category": "ì „ì²´"})
                collection.insert_many(data_list)
                print(f"ğŸ’¾ MongoDBì— {len(data_list)}ê°œ ìƒí’ˆ ì €ì¥ ì™„ë£Œ!")
            except Exception as e:
                print(f"âš ï¸ MongoDB ì €ì¥ ì‹¤íŒ¨: {e}")
        elif data_list:
            print("ğŸ’¾ MongoDB ì—°ê²° ë¶ˆê°€ - ë°ì´í„°ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤")
            for item in data_list[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                print(f"   ğŸ“¦ {item['rank']}. {item['product_name'][:30]}... - {item['price']}")
        else:
            print("âŒ ì¶”ì¶œëœ ìƒí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            print("ğŸ” í˜ì´ì§€ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ë¶„ì„í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        
        return data_list
        
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
    
    finally:
        driver.quit()
        print("ğŸ í¬ë¡¤ë§ ì™„ë£Œ")

if __name__ == "__main__":
    result = crawl_naver_best100_advanced()
    print(f"ğŸ“Š ìµœì¢… ê²°ê³¼: {len(result)}ê°œ ìƒí’ˆ") 