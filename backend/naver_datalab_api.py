"""
ë„¤ì´ë²„ ë°ì´í„°ë© APIë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ë¶„ì„
ë„¤ì´ë²„ ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ ë° ì—°ê´€ ê²€ìƒ‰ì–´ ì œê³µ
"""

import requests
import json
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import random
from naver_search_api import NaverSearchAPI

class NaverDatalabAPI:
    def __init__(self):
        # ë„¤ì´ë²„ ë°ì´í„°ë© API ì„¤ì • (ìƒˆë¡œ ë°œê¸‰ë°›ì€ í‚¤)
        self.client_id = "X7wUfrlR_w8ACIQE4Bae"  # ìƒˆë¡œ ë°œê¸‰ë°›ì€ í‚¤
        self.client_secret = "UI8_MuRzda"  # ìƒˆë¡œ ë°œê¸‰ë°›ì€ í‚¤
        self.base_url = "https://openapi.naver.com/v1/datalab/search"
        
        # ë„¤ì´ë²„ ê²€ìƒ‰ API ì¸ìŠ¤í„´ìŠ¤ ì¶”ê°€
        self.search_api = NaverSearchAPI()
        
        # API í‚¤ ìƒíƒœ í™•ì¸
        self.api_key_valid = False
        self._check_api_key()
    
    def _check_api_key(self):
        """API í‚¤ ìœ íš¨ì„± í™•ì¸"""
        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­ìœ¼ë¡œ API í‚¤ í™•ì¸
            test_data = {
                "startDate": "2024-01-01",
                "endDate": "2024-01-02",
                "timeUnit": "date",
                "keywordGroups": [
                    {
                        "groupName": "í…ŒìŠ¤íŠ¸",
                        "keywords": ["í…ŒìŠ¤íŠ¸"]
                    }
                ]
            }
            
            headers = {
                "X-Naver-Client-Id": self.client_id,
                "X-Naver-Client-Secret": self.client_secret,
                "Content-Type": "application/json"
            }
            
            response = requests.post(self.base_url, json=test_data, headers=headers, timeout=5)
            
            if response.status_code == 200:
                self.api_key_valid = True
                print("âœ… ë„¤ì´ë²„ ë°ì´í„°ë© API í‚¤ ìœ íš¨")
            else:
                self.api_key_valid = False
                print(f"âš ï¸ ë„¤ì´ë²„ ë°ì´í„°ë© API í‚¤ ë§Œë£Œ ë˜ëŠ” ì˜ëª»ë¨: {response.status_code}")
                
        except Exception as e:
            self.api_key_valid = False
            print(f"âš ï¸ ë„¤ì´ë²„ ë°ì´í„°ë© API í‚¤ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        
    def get_trend_data(self, keywords: List[str], start_date: str = None, end_date: str = None) -> Dict[str, Any]:
        """
        ë„¤ì´ë²„ ë°ì´í„°ë© APIë¡œ í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ
        
        Args:
            keywords (List[str]): ë¶„ì„í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            start_date (str): ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
            end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)
            
        Returns:
            Dict[str, Any]: íŠ¸ë Œë“œ ë°ì´í„°
        """
        # API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ëª©ì—… ë°ì´í„° ë°˜í™˜
        if not self.api_key_valid:
            print("âš ï¸ ë„¤ì´ë²„ ë°ì´í„°ë© API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šì•„ ëª©ì—… ë°ì´í„° ì‚¬ìš©")
            return self._get_mock_trend_data(keywords, start_date, end_date)
        
        # ë‚ ì§œ ì„¤ì • (ê¸°ë³¸ê°’: ìµœê·¼ 7ì¼)
        if not start_date:
            start_date = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
        if not end_date:
            end_date = datetime.now().strftime("%Y-%m-%d")
        
        # API ìš”ì²­ ë°ì´í„°
        data = {
            "startDate": start_date,
            "endDate": end_date,
            "timeUnit": "date",
            "keywordGroups": [
                {
                    "groupName": keyword,
                    "keywords": [keyword]
                } for keyword in keywords
            ]
        }
        
        headers = {
            "X-Naver-Client-Id": self.client_id,
            "X-Naver-Client-Secret": self.client_secret,
            "Content-Type": "application/json"
        }
        
        try:
            response = requests.post(self.base_url, json=data, headers=headers)
            response.raise_for_status()
            
            return response.json()
            
        except requests.exceptions.RequestException as e:
            print(f"âš ï¸ ë„¤ì´ë²„ ë°ì´í„°ë© API í˜¸ì¶œ ì‹¤íŒ¨, ëª©ì—… ë°ì´í„° ì‚¬ìš©: {str(e)}")
            return self._get_mock_trend_data(keywords, start_date, end_date)
    
    def _get_mock_trend_data(self, keywords: List[str], start_date: str, end_date: str) -> Dict[str, Any]:
        """ëª©ì—… íŠ¸ë Œë“œ ë°ì´í„° ìƒì„±"""
        # ì‹¤ì œì™€ ìœ ì‚¬í•œ ëª©ì—… ë°ì´í„° ìƒì„±
        mock_data = {
            "startDate": start_date,
            "endDate": end_date,
            "timeUnit": "date",
            "results": []
        }
        
        for keyword in keywords:
            # 7ì¼ê°„ì˜ íŠ¸ë Œë“œ ë°ì´í„° ìƒì„±
            keyword_data = {
                "title": keyword,
                "data": []
            }
            
            for i in range(7):
                date = (datetime.now() - timedelta(days=6-i)).strftime("%Y-%m-%d")
                # ì‹¤ì œì ì¸ íŠ¸ë Œë“œ íŒ¨í„´ ìƒì„±
                base_ratio = 50 + (len(keyword) * 2)  # í‚¤ì›Œë“œ ê¸¸ì´ì— ë”°ë¥¸ ê¸°ë³¸ê°’
                ratio = base_ratio + random.randint(-20, 30)  # ëœë¤ ë³€ë™
                ratio = max(10, min(100, ratio))  # 10-100 ë²”ìœ„ë¡œ ì œí•œ
                
                keyword_data["data"].append({
                    "period": date,
                    "ratio": ratio
                })
            
            mock_data["results"].append(keyword_data)
        
        return mock_data
    
    def get_related_keywords(self, keyword: str) -> List[Dict[str, Any]]:
        """
        ì—°ê´€ í‚¤ì›Œë“œ ë¶„ì„ (ë„¤ì´ë²„ ê²€ìƒ‰ API ì‚¬ìš©)
        
        Args:
            keyword (str): ë©”ì¸ í‚¤ì›Œë“œ
            
        Returns:
            List[Dict[str, Any]]: ì—°ê´€ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        # ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ ì—°ê´€ í‚¤ì›Œë“œ ì¶”ì¶œ
        print(f"ğŸ“Š '{keyword}' ì—°ê´€ í‚¤ì›Œë“œ ë¶„ì„ (ë„¤ì´ë²„ ê²€ìƒ‰ API ì‚¬ìš©)")
        
        try:
            # ë„¤ì´ë²„ ê²€ìƒ‰ APIì—ì„œ ì—°ê´€ í‚¤ì›Œë“œ ì¶”ì¶œ
            related_keywords = self.search_api.get_related_keywords_from_search(keyword)
            
            if related_keywords:
                print(f"âœ… ë„¤ì´ë²„ ê²€ìƒ‰ API ê¸°ë°˜ ì—°ê´€ í‚¤ì›Œë“œ {len(related_keywords)}ê°œ ìƒì„±")
                return related_keywords
        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ ê²€ìƒ‰ API ì‹¤íŒ¨, ëª©ì—… ë°ì´í„°ë¡œ ëŒ€ì²´: {str(e)}")
        
        # í´ë°±: ëª©ì—… ë°ì´í„° ì‚¬ìš©
        return self.get_related_keywords_mock(keyword)
    
    def _generate_related_keywords_from_trend(self, keyword: str, trend_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—°ê´€ í‚¤ì›Œë“œ ìƒì„±"""
        related_keywords = []
        
        # í‚¤ì›Œë“œ íŒ¨í„´ì— ë”°ë¥¸ ì—°ê´€ í‚¤ì›Œë“œ ìƒì„±
        keyword_patterns = {
            "ë¡œë´‡ì²­ì†Œê¸°": ["ìŠ¤ë§ˆíŠ¸ì²­ì†Œê¸°", "ë¬´ì„ ì²­ì†Œê¸°", "ìë™ì²­ì†Œê¸°", "ì²­ì†Œë¡œë´‡", "ì§‘ì•ˆì²­ì†Œ"],
            "ì—¬ë¦„ì›í”¼ìŠ¤": ["ì—¬ë¦„ì˜·", "ì›í”¼ìŠ¤", "ì—¬ë¦„íŒ¨ì…˜", "ì—¬ë¦„ìŠ¤íƒ€ì¼", "ì—¬ë¦„ì½”ë””"],
            "ìˆ˜ê±´": ["íƒ€ì›”", "ìš•ì‹¤ìš©í’ˆ", "ëª©ìš•ìš©í’ˆ", "ê±´ì¡°ìš©í’ˆ", "ìš•ì‹¤ìˆ˜ê±´"],
            "ë…¸íŠ¸ë¶": ["ì»´í“¨í„°", "ë©íƒ‘", "íœ´ëŒ€ìš©ì»´í“¨í„°", "ì „ìê¸°ê¸°", "ITì œí’ˆ"],
            "ìŠ¤ë§ˆíŠ¸í°": ["íœ´ëŒ€í°", "ëª¨ë°”ì¼", "ì „í™”ê¸°", "ë””ì§€í„¸ê¸°ê¸°", "í†µì‹ ê¸°ê¸°"]
        }
        
        # í‚¤ì›Œë“œ íŒ¨í„´ ë§¤ì¹­
        for pattern, related_list in keyword_patterns.items():
            if pattern in keyword or keyword in pattern:
                for i, related in enumerate(related_list):
                    # ì‹¤ì œ íŠ¸ë Œë“œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì—°ê´€ì„± ê³„ì‚°
                    relevance = max(60, 100 - (i * 10))  # ê¸°ë³¸ ì—°ê´€ì„±
                    
                    # íŠ¸ë Œë“œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—°ê´€ì„± ì¡°ì •
                    if trend_data and 'results' in trend_data:
                        relevance = min(95, relevance + 10)
                    
                    related_keywords.append({
                        'keyword': related,
                        'relevance': relevance,
                        'search_volume': f"{relevance * 10:,}",
                        'competition': 'ë³´í†µ' if relevance > 70 else 'ë‚®ìŒ'
                    })
                break
        
        # ê¸°ë³¸ ì—°ê´€ í‚¤ì›Œë“œ (íŒ¨í„´ì´ ì—†ëŠ” ê²½ìš°)
        if not related_keywords:
            base_keywords = [f"{keyword} ì¶”ì²œ", f"{keyword} ì¸ê¸°", f"{keyword} ìµœì‹ ", f"{keyword} ë¦¬ë·°", f"{keyword} ë¹„êµ"]
            for i, related in enumerate(base_keywords):
                relevance = max(50, 90 - (i * 8))
                related_keywords.append({
                    'keyword': related,
                    'relevance': relevance,
                    'search_volume': f"{relevance * 8:,}",
                    'competition': 'ë³´í†µ' if relevance > 60 else 'ë‚®ìŒ'
                })
        
        return related_keywords[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜
    
    def _get_search_volume_level(self, monthly_count: int) -> str:
        """
        ì›”ê°„ ê²€ìƒ‰ëŸ‰ì— ë”°ë¥¸ ê²€ìƒ‰ëŸ‰ ë ˆë²¨ ë°˜í™˜
        
        Args:
            monthly_count (int): ì›”ê°„ ê²€ìƒ‰ëŸ‰
            
        Returns:
            str: ê²€ìƒ‰ëŸ‰ ë ˆë²¨
        """
        if monthly_count >= 100000:
            return "ë§¤ìš° ë†’ìŒ"
        elif monthly_count >= 50000:
            return "ë†’ìŒ"
        elif monthly_count >= 10000:
            return "ë³´í†µ"
        elif monthly_count >= 1000:
            return "ë‚®ìŒ"
        else:
            return "ë§¤ìš° ë‚®ìŒ"
    
    def get_related_keywords_mock(self, keyword: str) -> List[Dict[str, Any]]:
        """
        ëª©ì—… ì—°ê´€ í‚¤ì›Œë“œ ë°ì´í„° (API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        
        Args:
            keyword (str): ë©”ì¸ í‚¤ì›Œë“œ
            
        Returns:
            List[Dict[str, Any]]: ì—°ê´€ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        # í‚¤ì›Œë“œë³„ ëª©ì—… ì—°ê´€ í‚¤ì›Œë“œ ë°ì´í„°
        related_keywords_map = {
            "ë¡œë´‡ì²­ì†Œê¸°": [
                {"keyword": "ì‚¼ì„± ë¡œë´‡ì²­ì†Œê¸°", "relevance": 95, "search_volume": "ë†’ìŒ"},
                {"keyword": "LG ë¡œë´‡ì²­ì†Œê¸°", "relevance": 92, "search_volume": "ë†’ìŒ"},
                {"keyword": "ë‹¤ì´ìŠ¨ ë¡œë´‡ì²­ì†Œê¸°", "relevance": 88, "search_volume": "ë³´í†µ"},
                {"keyword": "ë¡œë´‡ì²­ì†Œê¸° ì¶”ì²œ", "relevance": 85, "search_volume": "ë†’ìŒ"},
                {"keyword": "ë¡œë´‡ì²­ì†Œê¸° ë¹„êµ", "relevance": 82, "search_volume": "ë³´í†µ"}
            ],
            "ì—¬ë¦„ì›í”¼ìŠ¤": [
                {"keyword": "ì—¬ë¦„ì›í”¼ìŠ¤ ì¶”ì²œ", "relevance": 96, "search_volume": "ë§¤ìš° ë†’ìŒ"},
                {"keyword": "ì—¬ë¦„ì›í”¼ìŠ¤ ì‡¼í•‘ëª°", "relevance": 93, "search_volume": "ë†’ìŒ"},
                {"keyword": "ì—¬ë¦„ì›í”¼ìŠ¤ ë¸Œëœë“œ", "relevance": 89, "search_volume": "ë³´í†µ"},
                {"keyword": "ì—¬ë¦„ì›í”¼ìŠ¤ ì½”ë””", "relevance": 87, "search_volume": "ë†’ìŒ"},
                {"keyword": "ì—¬ë¦„ì›í”¼ìŠ¤ ì‚¬ì´ì¦ˆ", "relevance": 84, "search_volume": "ë³´í†µ"}
            ],
            "ìˆ˜ê±´": [
                {"keyword": "ìˆ˜ê±´ ì¶”ì²œ", "relevance": 94, "search_volume": "ë†’ìŒ"},
                {"keyword": "ìˆ˜ê±´ ì„¸íŠ¸", "relevance": 91, "search_volume": "ë³´í†µ"},
                {"keyword": "ìˆ˜ê±´ ë¸Œëœë“œ", "relevance": 88, "search_volume": "ë³´í†µ"},
                {"keyword": "ìˆ˜ê±´ êµ¬ë§¤", "relevance": 85, "search_volume": "ë³´í†µ"},
                {"keyword": "ìˆ˜ê±´ ë¹„êµ", "relevance": 82, "search_volume": "ë‚®ìŒ"}
            ]
        }
        
        if keyword in related_keywords_map:
            return related_keywords_map[keyword]
        else:
            # ê¸°ë³¸ ì—°ê´€ í‚¤ì›Œë“œ ìƒì„±
            return [
                {"keyword": f"{keyword} ì¶”ì²œ", "relevance": 90, "search_volume": "ë³´í†µ"},
                {"keyword": f"{keyword} ë¹„êµ", "relevance": 85, "search_volume": "ë³´í†µ"},
                {"keyword": f"{keyword} ë¸Œëœë“œ", "relevance": 80, "search_volume": "ë³´í†µ"},
                {"keyword": f"{keyword} êµ¬ë§¤", "relevance": 75, "search_volume": "ë³´í†µ"},
                {"keyword": f"{keyword} ë¦¬ë·°", "relevance": 70, "search_volume": "ë³´í†µ"}
            ]
    
    def get_search_volume_stats(self, keyword: str) -> Dict[str, Any]:
        """
        ê²€ìƒ‰ëŸ‰ í†µê³„ ë¶„ì„ (ë„¤ì´ë²„ ê²€ìƒ‰ API ì‚¬ìš©)
        
        Args:
            keyword (str): ë¶„ì„í•  í‚¤ì›Œë“œ
            
        Returns:
            Dict[str, Any]: ê²€ìƒ‰ëŸ‰ í†µê³„
        """
        # ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ ê²€ìƒ‰ëŸ‰ í†µê³„
        print(f"ğŸ“Š '{keyword}' ê²€ìƒ‰ëŸ‰ í†µê³„ ë¶„ì„ (ë„¤ì´ë²„ ê²€ìƒ‰ API ì‚¬ìš©)")
        
        try:
            # ë„¤ì´ë²„ ê²€ìƒ‰ APIì—ì„œ ê²€ìƒ‰ëŸ‰ í†µê³„ ìƒì„±
            search_volume = self.search_api.get_search_volume_from_search(keyword)
            
            if search_volume:
                print(f"âœ… ë„¤ì´ë²„ ê²€ìƒ‰ API ê¸°ë°˜ ê²€ìƒ‰ëŸ‰ í†µê³„ ìƒì„±")
                return search_volume
        except Exception as e:
            print(f"âš ï¸ ë„¤ì´ë²„ ê²€ìƒ‰ API ì‹¤íŒ¨, ëª©ì—… ë°ì´í„°ë¡œ ëŒ€ì²´: {str(e)}")
        
        # í´ë°±: ëª©ì—… ë°ì´í„° ì‚¬ìš©
        return self.get_search_volume_stats_mock(keyword)
    
    def _generate_search_volume_from_trend(self, keyword: str, trend_data: Dict[str, Any]) -> Dict[str, Any]:
        """íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ëŸ‰ í†µê³„ ìƒì„±"""
        # ê¸°ë³¸ ê²€ìƒ‰ëŸ‰ (í‚¤ì›Œë“œ ê¸¸ì´ì™€ ë³µì¡ì„±ì— ë”°ë¼ ì¡°ì •)
        base_volume = len(keyword) * 1000
        
        # íŠ¸ë Œë“œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ëŸ‰ ì¡°ì •
        if trend_data and 'results' in trend_data:
            results = trend_data['results']
            if results and len(results) > 0:
                # ì‹¤ì œ íŠ¸ë Œë“œ ë°ì´í„° ê¸°ë°˜ ê²€ìƒ‰ëŸ‰ ê³„ì‚°
                avg_trend = sum(result.get('ratio', 0) for result in results) / len(results)
                base_volume = int(base_volume * (avg_trend / 100 + 0.5))
        
        # ê²€ìƒ‰ëŸ‰ ë ˆë²¨ ê²°ì •
        if base_volume > 50000:
            volume_level = "ë§¤ìš° ë†’ìŒ"
            competition = "ë†’ìŒ"
        elif base_volume > 20000:
            volume_level = "ë†’ìŒ"
            competition = "ë³´í†µ"
        elif base_volume > 5000:
            volume_level = "ë³´í†µ"
            competition = "ë³´í†µ"
        else:
            volume_level = "ë‚®ìŒ"
            competition = "ë‚®ìŒ"
        
        return {
            'daily_searches': base_volume,
            'weekly_searches': base_volume * 7,  # ì£¼ê°„ ê²€ìƒ‰ëŸ‰ ì¶”ê°€
            'monthly_searches': base_volume * 30,
            'volume_level': volume_level,
            'competition': competition,
            'trend_direction': 'ìƒìŠ¹' if base_volume > 10000 else 'ì•ˆì •',
            'growth_rate': f"{max(5, min(50, base_volume // 1000))}%",
            'seasonality': 'ì—°ì¤‘'  # ê¸°ë³¸ê°’
        }
    
    def _get_trend_from_data(self, keyword_data: Dict[str, Any]) -> str:
        """
        í‚¤ì›Œë“œ ë°ì´í„°ì—ì„œ íŠ¸ë Œë“œ ë°©í–¥ ì¶”ì¶œ
        
        Args:
            keyword_data (Dict[str, Any]): í‚¤ì›Œë“œ ë°ì´í„°
            
        Returns:
            str: íŠ¸ë Œë“œ ë°©í–¥
        """
        # ì‹¤ì œë¡œëŠ” ì›”ë³„ ë°ì´í„° ë¹„êµê°€ í•„ìš”í•˜ì§€ë§Œ, í˜„ì¬ëŠ” ê¸°ë³¸ê°’ ë°˜í™˜
        return "ìƒìŠ¹"  # ê¸°ë³¸ê°’
    
    def _get_competition_level(self, keyword_data: Dict[str, Any]) -> str:
        """
        í‚¤ì›Œë“œ ë°ì´í„°ì—ì„œ ê²½ìŸë„ ë ˆë²¨ ì¶”ì¶œ
        
        Args:
            keyword_data (Dict[str, Any]): í‚¤ì›Œë“œ ë°ì´í„°
            
        Returns:
            str: ê²½ìŸë„ ë ˆë²¨
        """
        monthly_count = keyword_data.get('monthlyPcQtyCnt', 0) + keyword_data.get('monthlyMobileQtyCnt', 0)
        
        if monthly_count >= 100000:
            return "ë§¤ìš° ë†’ìŒ"
        elif monthly_count >= 50000:
            return "ë†’ìŒ"
        elif monthly_count >= 10000:
            return "ë³´í†µ"
        else:
            return "ë‚®ìŒ"
    
    def get_search_volume_stats_mock(self, keyword: str) -> Dict[str, Any]:
        """
        ëª©ì—… ê²€ìƒ‰ëŸ‰ í†µê³„ ë°ì´í„° (API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        
        Args:
            keyword (str): ë¶„ì„í•  í‚¤ì›Œë“œ
            
        Returns:
            Dict[str, Any]: ê²€ìƒ‰ëŸ‰ í†µê³„
        """
        # ëª©ì—… ê²€ìƒ‰ëŸ‰ ë°ì´í„°
        search_volume_map = {
            "ë¡œë´‡ì²­ì†Œê¸°": {
                "daily_searches": 8500,
                "weekly_searches": 59500,
                "monthly_searches": 255000,
                "trend": "ìƒìŠ¹",
                "competition": "ë†’ìŒ",
                "seasonality": "ì—°ì¤‘"
            },
            "ì—¬ë¦„ì›í”¼ìŠ¤": {
                "daily_searches": 12000,
                "weekly_searches": 84000,
                "monthly_searches": 360000,
                "trend": "ìƒìŠ¹",
                "competition": "ë§¤ìš° ë†’ìŒ",
                "seasonality": "ê³„ì ˆì„±"
            },
            "ìˆ˜ê±´": {
                "daily_searches": 3200,
                "weekly_searches": 22400,
                "monthly_searches": 96000,
                "trend": "ìœ ì§€",
                "competition": "ë³´í†µ",
                "seasonality": "ì—°ì¤‘"
            }
        }
        
        if keyword in search_volume_map:
            return search_volume_map[keyword]
        else:
            # ê¸°ë³¸ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ìƒì„±
            daily = random.randint(1000, 5000)
            return {
                "daily_searches": daily,
                "weekly_searches": daily * 7,
                "monthly_searches": daily * 30,
                "trend": random.choice(["ìƒìŠ¹", "í•˜ë½", "ìœ ì§€"]),
                "competition": random.choice(["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"]),
                "seasonality": random.choice(["ì—°ì¤‘", "ê³„ì ˆì„±"])
            }
    
    def get_trend_chart_data_real(self, keyword: str) -> List[Dict[str, Any]]:
        """
        ì‹¤ì œ APIë¥¼ ì‚¬ìš©í•œ íŠ¸ë Œë“œ ì°¨íŠ¸ ë°ì´í„°
        
        Args:
            keyword (str): í‚¤ì›Œë“œ
            
        Returns:
            List[Dict[str, Any]]: 7ì¼ íŠ¸ë Œë“œ ë°ì´í„°
        """
        try:
            # ë„¤ì´ë²„ ë°ì´í„°ë© APIì—ì„œ ì‹¤ì œ 7ì¼ íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ
            trend_data = self.get_trend_data([keyword])
            return self._parse_trend_chart_data(trend_data, keyword)
        except Exception as e:
            print(f"âš ï¸ ì‹¤ì œ íŠ¸ë Œë“œ ì°¨íŠ¸ API í˜¸ì¶œ ì‹¤íŒ¨, ëª©ì—… ë°ì´í„°ë¡œ ëŒ€ì²´: {str(e)}")
            return self.get_trend_chart_data_mock(keyword)
    
    def _parse_trend_chart_data(self, trend_data: Dict[str, Any], keyword: str) -> List[Dict[str, Any]]:
        """
        ì‹¤ì œ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ì°¨íŠ¸ìš©ìœ¼ë¡œ íŒŒì‹±
        
        Args:
            trend_data (Dict[str, Any]): ë„¤ì´ë²„ ë°ì´í„°ë© API ì‘ë‹µ
            keyword (str): í‚¤ì›Œë“œ
            
        Returns:
            List[Dict[str, Any]]: ì°¨íŠ¸ìš© ë°ì´í„°
        """
        try:
            results = trend_data.get('results', [])
            if not results:
                return self.get_trend_chart_data_mock(keyword)
            
            keyword_data = results[0]
            data_points = keyword_data.get('data', [])
            
            chart_data = []
            for point in data_points:
                chart_data.append({
                    'date': point.get('period', ''),
                    'trend': point.get('ratio', 0)
                })
            
            return chart_data
        except Exception as e:
            return self.get_trend_chart_data_mock(keyword)
    
    def get_trend_chart_data_mock(self, keyword: str) -> List[Dict[str, Any]]:
        """
        ëª©ì—… íŠ¸ë Œë“œ ì°¨íŠ¸ ë°ì´í„° (API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        
        Args:
            keyword (str): í‚¤ì›Œë“œ
            
        Returns:
            List[Dict[str, Any]]: 7ì¼ íŠ¸ë Œë“œ ë°ì´í„°
        """
        # ëª©ì—… 7ì¼ íŠ¸ë Œë“œ ë°ì´í„° ìƒì„±
        chart_data = []
        base_trend = random.randint(30, 80)
        
        for i in range(7):
            date = datetime.now() - timedelta(days=6-i)
            trend_value = base_trend + random.randint(-10, 10)
            trend_value = max(0, min(100, trend_value))
            
            chart_data.append({
                'date': date.strftime('%m/%d'),
                'trend': trend_value
            })
        
        return chart_data
    
    def get_keyword_analysis(self, keyword: str) -> Dict[str, Any]:
        """
        í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ë°˜í™˜ (í™•ì¥ëœ ë²„ì „)
        
        Args:
            keyword (str): ë¶„ì„í•  í‚¤ì›Œë“œ
            
        Returns:
            Dict[str, Any]: í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
        """
        try:
            # íŠ¸ë Œë“œ ë°ì´í„° ì¡°íšŒ
            trend_data = self.get_trend_data([keyword])
            
            # ë°ì´í„° íŒŒì‹±
            parsed_data = self.parse_trend_data(trend_data, keyword)
            
            # ì—°ê´€ í‚¤ì›Œë“œ ë¶„ì„ ì¶”ê°€
            related_keywords = self.get_related_keywords(keyword)
            
            # ê²€ìƒ‰ëŸ‰ í†µê³„ ì¶”ê°€
            search_volume_stats = self.get_search_volume_stats(keyword)
            
            # í™•ì¥ëœ ë¶„ì„ ê²°ê³¼
            extended_analysis = {
                **parsed_data,
                'related_keywords': related_keywords,
                'search_volume_stats': search_volume_stats,
                'analysis_insights': self.generate_insights(keyword, parsed_data, related_keywords, search_volume_stats)
            }
            
            return extended_analysis
            
        except Exception as e:
            # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ëª©ì—… ë°ì´í„°ë¡œ í´ë°±
            print(f"âš ï¸ ë„¤ì´ë²„ ë°ì´í„°ë© API í˜¸ì¶œ ì‹¤íŒ¨, ëª©ì—… ë°ì´í„°ë¡œ ëŒ€ì²´: {str(e)}")
            return self.get_mock_data(keyword)
    
    def generate_insights(self, keyword: str, trend_data: Dict, related_keywords: List, search_volume: Dict) -> List[str]:
        """
        í‚¤ì›Œë“œ ë¶„ì„ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        
        Args:
            keyword (str): í‚¤ì›Œë“œ
            trend_data (Dict): íŠ¸ë Œë“œ ë°ì´í„°
            related_keywords (List): ì—°ê´€ í‚¤ì›Œë“œ
            search_volume (Dict): ê²€ìƒ‰ëŸ‰ í†µê³„
            
        Returns:
            List[str]: ì¸ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        insights = []
        
        # íŠ¸ë Œë“œ ì¸ì‚¬ì´íŠ¸
        trend_score = trend_data['summary']['trend_score']
        trend_direction = trend_data['summary']['trend_direction']
        
        if trend_score >= 70:
            insights.append(f"'{keyword}'ëŠ” í˜„ì¬ ë§¤ìš° ì¸ê¸° ìˆëŠ” í‚¤ì›Œë“œì…ë‹ˆë‹¤.")
        elif trend_score >= 50:
            insights.append(f"'{keyword}'ëŠ” ë³´í†µ ìˆ˜ì¤€ì˜ ì¸ê¸°ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
        else:
            insights.append(f"'{keyword}'ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì¸ê¸°ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
        
        if trend_direction == "ìƒìŠ¹":
            insights.append("íŠ¸ë Œë“œê°€ ìƒìŠ¹í•˜ê³  ìˆì–´ ê´€ì‹¬ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        elif trend_direction == "í•˜ë½":
            insights.append("íŠ¸ë Œë“œê°€ í•˜ë½í•˜ê³  ìˆì–´ ê´€ì‹¬ì´ ê°ì†Œí•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ê²€ìƒ‰ëŸ‰ ì¸ì‚¬ì´íŠ¸
        daily_searches = search_volume['daily_searches']
        if daily_searches >= 10000:
            insights.append("ì¼ì¼ ê²€ìƒ‰ëŸ‰ì´ ë§¤ìš° ë†’ì•„ ê²½ìŸì´ ì¹˜ì—´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif daily_searches >= 5000:
            insights.append("ì¼ì¼ ê²€ìƒ‰ëŸ‰ì´ ë†’ì•„ ë§ˆì¼€íŒ… ê¸°íšŒê°€ ìˆìŠµë‹ˆë‹¤.")
        else:
            insights.append("ì¼ì¼ ê²€ìƒ‰ëŸ‰ì´ ë³´í†µ ìˆ˜ì¤€ìœ¼ë¡œ ì•ˆì •ì ì…ë‹ˆë‹¤.")
        
        # ì—°ê´€ í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸
        if related_keywords:
            top_related = related_keywords[0]['keyword']
            insights.append(f"ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ì€ í‚¤ì›Œë“œëŠ” '{top_related}'ì…ë‹ˆë‹¤.")
        
        # ê³„ì ˆì„± ì¸ì‚¬ì´íŠ¸
        if 'seasonality' in search_volume and search_volume['seasonality'] == "ê³„ì ˆì„±":
            insights.append("ì´ í‚¤ì›Œë“œëŠ” ê³„ì ˆì  íŠ¹ì„±ì„ ë³´ì´ë¯€ë¡œ ì‹œê¸°ë³„ ë§ˆì¼€íŒ… ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            insights.append("ì´ í‚¤ì›Œë“œëŠ” ì—°ì¤‘ ì•ˆì •ì ì¸ ê´€ì‹¬ì„ ë³´ì…ë‹ˆë‹¤.")
        
        return insights
    
    def parse_trend_data(self, trend_data: Dict[str, Any], keyword: str) -> Dict[str, Any]:
        """
        íŠ¸ë Œë“œ ë°ì´í„° íŒŒì‹±
        
        Args:
            trend_data (Dict[str, Any]): ë„¤ì´ë²„ ë°ì´í„°ë© API ì‘ë‹µ
            keyword (str): ê²€ìƒ‰ í‚¤ì›Œë“œ
            
        Returns:
            Dict[str, Any]: íŒŒì‹±ëœ ë°ì´í„°
        """
        try:
            results = trend_data.get('results', [])
            
            if not results:
                return self.get_mock_data(keyword)
            
            # ì²« ë²ˆì§¸ í‚¤ì›Œë“œ ê·¸ë£¹ì˜ ë°ì´í„° ì¶”ì¶œ
            keyword_data = results[0]
            data_points = keyword_data.get('data', [])
            
            # íŠ¸ë Œë“œ ë¶„ì„
            if data_points:
                # ìµœê·¼ 7ì¼ í‰ê·  íŠ¸ë Œë“œ
                recent_trends = [point.get('ratio', 0) for point in data_points[-7:]]
                avg_trend = sum(recent_trends) / len(recent_trends) if recent_trends else 0
                
                # ìµœê³  íŠ¸ë Œë“œ
                max_trend = max([point.get('ratio', 0) for point in data_points]) if data_points else 0
                
                # íŠ¸ë Œë“œ ë°©í–¥ (ìƒìŠ¹/í•˜ë½/ìœ ì§€)
                if len(data_points) >= 2:
                    first_trend = data_points[0].get('ratio', 0)
                    last_trend = data_points[-1].get('ratio', 0)
                    if last_trend > first_trend:
                        trend_direction = "ìƒìŠ¹"
                    elif last_trend < first_trend:
                        trend_direction = "í•˜ë½"
                    else:
                        trend_direction = "ìœ ì§€"
                else:
                    trend_direction = "ìœ ì§€"
            else:
                avg_trend = 0
                max_trend = 0
                trend_direction = "ìœ ì§€"
            
            # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
            analysis_result = {
                'search_keyword': keyword,
                'trend_analysis': {
                    'avg_trend': round(avg_trend, 2),
                    'max_trend': round(max_trend, 2),
                    'trend_direction': trend_direction,
                    'data_points': len(data_points)
                },
                'summary': {
                    'keyword': keyword,
                    'trend_score': round(avg_trend, 2),
                    'popularity': self.get_popularity_level(avg_trend),
                    'trend_direction': trend_direction
                }
            }
            
            return analysis_result
            
        except Exception as e:
            raise Exception(f"íŠ¸ë Œë“œ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    
    def get_popularity_level(self, trend_score: float) -> str:
        """
        íŠ¸ë Œë“œ ì ìˆ˜ì— ë”°ë¥¸ ì¸ê¸°ë„ ë ˆë²¨ ë°˜í™˜
        
        Args:
            trend_score (float): íŠ¸ë Œë“œ ì ìˆ˜
            
        Returns:
            str: ì¸ê¸°ë„ ë ˆë²¨
        """
        if trend_score >= 80:
            return "ë§¤ìš° ë†’ìŒ"
        elif trend_score >= 60:
            return "ë†’ìŒ"
        elif trend_score >= 40:
            return "ë³´í†µ"
        elif trend_score >= 20:
            return "ë‚®ìŒ"
        else:
            return "ë§¤ìš° ë‚®ìŒ"
    
    def get_mock_data(self, keyword: str) -> Dict[str, Any]:
        """
        ëª©ì—… ë°ì´í„° ë°˜í™˜ (API ì‹¤íŒ¨ ì‹œ) - í™•ì¥ëœ ë²„ì „
        
        Args:
            keyword (str): í‚¤ì›Œë“œ
            
        Returns:
            Dict[str, Any]: ëª©ì—… ë°ì´í„°
        """
        # í‚¤ì›Œë“œë³„ ëª©ì—… íŠ¸ë Œë“œ ë°ì´í„°
        mock_trends = {
            "ì—¬ë¦„ì›í”¼ìŠ¤": {"avg_trend": 85.5, "max_trend": 95.2, "trend_direction": "ìƒìŠ¹"},
            "ìˆ˜ê±´": {"avg_trend": 45.3, "max_trend": 52.1, "trend_direction": "ìœ ì§€"},
            "ê°•ì•„ì§€": {"avg_trend": 72.8, "max_trend": 88.9, "trend_direction": "ìƒìŠ¹"},
            "í…ŒìŠ¤íŠ¸": {"avg_trend": 25.1, "max_trend": 30.5, "trend_direction": "í•˜ë½"}
        }
        
        if keyword in mock_trends:
            trend_data = mock_trends[keyword]
        else:
            trend_data = {"avg_trend": 50.0, "max_trend": 60.0, "trend_direction": "ìœ ì§€"}
        
        # ê¸°ë³¸ ë¶„ì„ ê²°ê³¼
        basic_analysis = {
            'search_keyword': keyword,
            'trend_analysis': {
                'avg_trend': trend_data['avg_trend'],
                'max_trend': trend_data['max_trend'],
                'trend_direction': trend_data['trend_direction'],
                'data_points': 7
            },
            'summary': {
                'keyword': keyword,
                'trend_score': trend_data['avg_trend'],
                'popularity': self.get_popularity_level(trend_data['avg_trend']),
                'trend_direction': trend_data['trend_direction']
            }
        }
        
        # ì—°ê´€ í‚¤ì›Œë“œ ì¶”ê°€
        related_keywords = self.get_related_keywords_mock(keyword)
        
        # ê²€ìƒ‰ëŸ‰ í†µê³„ ì¶”ê°€
        search_volume_stats = self.get_search_volume_stats_mock(keyword)
        
        # ì¸ì‚¬ì´íŠ¸ ìƒì„±
        analysis_insights = self.generate_insights(keyword, basic_analysis, related_keywords, search_volume_stats)
        
        # í™•ì¥ëœ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
        return {
            **basic_analysis,
            'related_keywords': related_keywords,
            'search_volume_stats': search_volume_stats,
            'analysis_insights': analysis_insights
        }
    
    def test_api_connection(self) -> Dict[str, Any]:
        """
        API ì—°ê²° í…ŒìŠ¤íŠ¸
        
        Returns:
            Dict[str, Any]: í…ŒìŠ¤íŠ¸ ê²°ê³¼
        """
        try:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œë¡œ í…ŒìŠ¤íŠ¸
            test_keyword = "í…ŒìŠ¤íŠ¸"
            result = self.get_keyword_analysis(test_keyword)
            
            return {
                'status': 'success',
                'message': 'ë„¤ì´ë²„ ë°ì´í„°ë© API ì—°ê²° ì„±ê³µ',
                'test_keyword': test_keyword,
                'trend_score': result['summary']['trend_score'],
                'popularity': result['summary']['popularity']
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': f'ë„¤ì´ë²„ ë°ì´í„°ë© API ì—°ê²° ì‹¤íŒ¨: {str(e)}',
                'test_keyword': 'í…ŒìŠ¤íŠ¸',
                'trend_score': 0,
                'popularity': 'ì•Œ ìˆ˜ ì—†ìŒ'
            } 